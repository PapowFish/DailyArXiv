---
title: Latest 15 Papers - November 17, 2025
labels: documentation
---
**Please check the [Github](https://github.com/PapowFish/DailyArXiv) page for a better reading experience and more papers.**

## Video Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[DreamRunner: Fine-Grained Compositional Story-to-Video Generation with Retrieval-Augmented Motion Adaptation](https://arxiv.org/abs/2411.16657v4)** | 2025-11-14 | <details><summary>AAAI ...</summary><p>AAAI 2026, Project website: https://zunwang1.github.io/DreamRunner</p></details> |
| **[Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202v2)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted in IJCNLP-AACL 2025 (also presented in MAGMAR 2025 at ACL 2025)</p></details> |
| **[LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts](https://arxiv.org/abs/2505.13928v3)** | 2025-11-13 |  |
| **[Explicit Temporal-Semantic Modeling for Dense Video Captioning via Context-Aware Cross-Modal Interaction](https://arxiv.org/abs/2511.10134v1)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted to AAAI 2026</p></details> |
| **[Learning a Thousand Tasks in a Day](https://arxiv.org/abs/2511.10110v1)** | 2025-11-13 | <details><summary>This ...</summary><p>This is the author's version of the work. It is posted here by permission of the AAAS for personal use, not for redistribution. The definitive version was published in Science Robotics on 12 November 2025, DOI: https://www.science.org/doi/10.1126/scirobotics.adv7594. Link to project website: https://www.robot-learning.uk/learning-1000-tasks</p></details> |
| **[Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction](https://arxiv.org/abs/2511.07392v2)** | 2025-11-11 | <details><summary>22 pa...</summary><p>22 pages, 12 figures, 1 table, Supplementary Information</p></details> |
| **[Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model](https://arxiv.org/abs/2503.09205v4)** | 2025-11-10 | <details><summary>Accep...</summary><p>Accepted at EUSIPCO 2025 - 5 pages, 5 figures, 2 tables</p></details> |
| **[StreamKV: Streaming Video Question-Answering with Segment-based KV Cache Retrieval and Compression](https://arxiv.org/abs/2511.07278v1)** | 2025-11-10 |  |
| **[Enhanced Partially Relevant Video Retrieval through Inter- and Intra-Sample Analysis with Coherence Prediction](https://arxiv.org/abs/2504.19637v3)** | 2025-11-10 | <details><summary>Upon ...</summary><p>Upon further consideration, we have concluded that the current version requires revision and may not yet be ready for publication. We plan to conduct additional experiments and make necessary improvements to ensure the paper meets the standards for future submission</p></details> |
| **[Video CLIP Model for Multi-View Echocardiography Interpretation](https://arxiv.org/abs/2504.18800v3)** | 2025-11-08 |  |
| **[On the Brittleness of CLIP Text Encoders](https://arxiv.org/abs/2511.04247v2)** | 2025-11-07 | <details><summary>Accep...</summary><p>Accepted for publication at MMM'26. Analysis code can be found here: https://github.com/allie-tran/clip-brittleness</p></details> |
| **[Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation](https://arxiv.org/abs/2511.05199v1)** | 2025-11-07 | <details><summary>Accep...</summary><p>Accepted by IROS 2025</p></details> |
| **[DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281v1)** | 2025-11-06 |  |
| **[Learning from Online Videos at Inference Time for Computer-Use Agents](https://arxiv.org/abs/2511.04137v1)** | 2025-11-06 |  |
| **[Caption Injection for Optimization in Generative Search Engine](https://arxiv.org/abs/2511.04080v1)** | 2025-11-06 |  |

## Multimodal Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MOON Embedding: Multimodal Representation Learning for E-commerce Search Advertising](https://arxiv.org/abs/2511.11305v1)** | 2025-11-14 | 31 pages, 12 figures |
| **[Positional Bias in Multimodal Embedding Models: Do They Favor the Beginning, the Middle, or the End?](https://arxiv.org/abs/2511.11216v1)** | 2025-11-14 | <details><summary>accep...</summary><p>accepted to AAAI 2026 main track</p></details> |
| **[Hindsight Distillation Reasoning with Knowledge Encouragement Preference for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2511.11132v1)** | 2025-11-14 |  |
| **[Multimodal Peer Review Simulation with Actionable To-Do Recommendations for Community-Aware Manuscript Revisions](https://arxiv.org/abs/2511.10902v1)** | 2025-11-14 |  |
| **[Q2E: Query-to-Event Decomposition for Zero-Shot Multilingual Text-to-Video Retrieval](https://arxiv.org/abs/2506.10202v2)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted in IJCNLP-AACL 2025 (also presented in MAGMAR 2025 at ACL 2025)</p></details> |
| **[URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552v1)** | 2025-11-13 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026 (Oral)</p></details> |
| **[Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711v2)** | 2025-11-13 |  |
| **[MonkeyOCR v1.5 Technical Report: Unlocking Robust Document Parsing for Complex Patterns](https://arxiv.org/abs/2511.10390v1)** | 2025-11-13 |  |
| **[LoVR: A Benchmark for Long Video Retrieval in Multimodal Contexts](https://arxiv.org/abs/2505.13928v3)** | 2025-11-13 |  |
| **[SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations](https://arxiv.org/abs/2511.09804v1)** | 2025-11-12 | <details><summary>32 pa...</summary><p>32 pages, 14 figures, accepted into EAAI 2026</p></details> |
| **[History Rhymes: Macro-Contextual Retrieval for Robust Financial Forecasting](https://arxiv.org/abs/2511.09754v1)** | 2025-11-12 | <details><summary>Accep...</summary><p>Accepted in IEEE BigData 2025</p></details> |
| **[NeuroCLIP: Brain-Inspired Prompt Tuning for EEG-to-Image Multimodal Contrastive Learning](https://arxiv.org/abs/2511.09250v1)** | 2025-11-12 |  |
| **[A Multimodal Recaptioning Framework to Account for Perceptual Diversity Across Languages in Vision-Language Modeling](https://arxiv.org/abs/2504.14359v2)** | 2025-11-11 | <details><summary>Accep...</summary><p>Accepted at IJCNLP-AACL 2025 (Main)</p></details> |
| **[Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding](https://arxiv.org/abs/2511.08480v1)** | 2025-11-11 | Multimodal Embedding |
| **[MARC: Multimodal and Multi-Task Agentic Retrieval-Augmented Generation for Cold-Start Recommender System](https://arxiv.org/abs/2511.08181v1)** | 2025-11-11 | <details><summary>13 pa...</summary><p>13 pages, 2 figures, Accepted at RDGENAI at CIKM 2025 workshop</p></details> |

