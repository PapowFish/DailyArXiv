---
title: Latest 15 Papers - December 02, 2025
labels: documentation
---
**Please check the [Github](https://github.com/PapowFish/DailyArXiv) page for a better reading experience and more papers.**

## Video Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Adaptive Evidential Learning for Temporal-Semantic Robustness in Moment Retrieval](https://arxiv.org/abs/2512.00953v1)** | 2025-11-30 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026, 10 pages, 9 figures, 5 tables</p></details> |
| **[CourseTimeQA: A Lecture-Video Benchmark and a Latency-Constrained Cross-Modal Fusion Method for Timestamped QA](https://arxiv.org/abs/2512.00360v1)** | 2025-11-29 | 5 figures, 8 tables |
| **[See, Rank, and Filter: Important Word-Aware Clip Filtering via Scene Understanding for Moment Retrieval and Highlight Detection](https://arxiv.org/abs/2511.22906v1)** | 2025-11-28 |  |
| **[Enhanced Partially Relevant Video Retrieval through Inter- and Intra-Sample Analysis with Coherence Prediction](https://arxiv.org/abs/2504.19637v5)** | 2025-11-28 |  |
| **[Captain Safari: A World Engine](https://arxiv.org/abs/2511.22815v1)** | 2025-11-28 |  |
| **[ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2511.22715v1)** | 2025-11-27 |  |
| **[Qwen3-VL Technical Report](https://arxiv.org/abs/2511.21631v2)** | 2025-11-27 | 42 pages |
| **[Watch and Learn: Learning to Use Computers from Online Videos](https://arxiv.org/abs/2510.04673v2)** | 2025-11-27 |  |
| **[F.A.C.U.L.: Language-Based Interaction with AI Companions in Gaming](https://arxiv.org/abs/2511.13112v2)** | 2025-11-27 | <details><summary>14 pa...</summary><p>14 pages, 11 figures,</p></details> |
| **[Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination](https://arxiv.org/abs/2511.17490v3)** | 2025-11-26 |  |
| **[TrafficLens: Multi-Camera Traffic Video Analysis Using LLMs](https://arxiv.org/abs/2511.20965v1)** | 2025-11-26 | <details><summary>2024 ...</summary><p>2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)</p></details> |
| **[Unsupervised Memorability Modeling from Tip-of-the-Tongue Retrieval Queries](https://arxiv.org/abs/2511.20854v1)** | 2025-11-25 | <details><summary>Accep...</summary><p>Accepted at WACV 2026</p></details> |
| **[LongVT: Incentivizing "Thinking with Long Videos" via Native Tool Calling](https://arxiv.org/abs/2511.20785v1)** | 2025-11-25 |  |
| **[Adversarial Robustness for Unified Multi-Modal Encoders via Efficient Calibration](https://arxiv.org/abs/2505.11895v2)** | 2025-11-25 |  |
| **[Back to the Feature: Explaining Video Classifiers with Video Counterfactual Explanations](https://arxiv.org/abs/2511.20295v1)** | 2025-11-25 |  |

## Multimodal Retrieval
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Augmenting Intra-Modal Understanding in MLLMs for Robust Multimodal Keyphrase Generation](https://arxiv.org/abs/2512.00928v1)** | 2025-11-30 |  |
| **[CART: A Generative Cross-Modal Retrieval Framework with Coarse-To-Fine Semantic Modeling](https://arxiv.org/abs/2406.17507v3)** | 2025-11-30 | <details><summary>Updat...</summary><p>Updated a few baseline metrics based on original publications. Conclusions unchanged</p></details> |
| **[Multilingual Training-Free Remote Sensing Image Captioning](https://arxiv.org/abs/2512.00887v1)** | 2025-11-30 |  |
| **[Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing](https://arxiv.org/abs/2512.00881v1)** | 2025-11-30 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |
| **[MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999v4)** | 2025-11-29 | <details><summary>Accep...</summary><p>Accepted by WSDM 2026. 11 pages, 9 figures</p></details> |
| **[Does Understanding Inform Generation in Unified Multimodal Models? From Analysis to Path Forward](https://arxiv.org/abs/2511.20561v2)** | 2025-11-29 |  |
| **[CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning](https://arxiv.org/abs/2512.00496v1)** | 2025-11-29 | <details><summary>25 pa...</summary><p>25 pages, 12 tables, 5 figures</p></details> |
| **[Look as You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://arxiv.org/abs/2511.12003v2)** | 2025-11-29 | Poster of AAAI'2026 |
| **[Words into World: A Task-Adaptive Agent for Language-Guided Spatial Retrieval in AR](https://arxiv.org/abs/2512.00294v1)** | 2025-11-29 |  |
| **[RealAppliance: Let High-fidelity Appliance Assets Controllable and Workable as Aligned Real Manuals](https://arxiv.org/abs/2512.00287v1)** | 2025-11-29 |  |
| **[LFM2 Technical Report](https://arxiv.org/abs/2511.23404v1)** | 2025-11-28 |  |
| **[See, Rank, and Filter: Important Word-Aware Clip Filtering via Scene Understanding for Moment Retrieval and Highlight Detection](https://arxiv.org/abs/2511.22906v1)** | 2025-11-28 |  |
| **[Resolving Evidence Sparsity: Agentic Context Engineering for Long-Document Understanding](https://arxiv.org/abs/2511.22850v1)** | 2025-11-28 |  |
| **[Breaking the Visual Shortcuts in Multimodal Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2511.22843v1)** | 2025-11-28 |  |
| **[ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2511.22715v1)** | 2025-11-27 |  |

